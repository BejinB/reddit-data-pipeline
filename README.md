# reddit-data-pipeline

## ğŸš€End-to-End Reddit Data Pipeline using Apache Airflow, Celery, PostgreSQL and AWS Services(S3, Glue, Crawler, Athena, Redshift & QuickSight)

This project is a fully orchestrated, production-style data pipeline built to extract Reddit post data, transform it, and visualize insights using various AWS services. The pipeline simulates a real-world scenario by integrating tools for scheduling, processing, storing, and visualizing data at scale.
## ğŸ“Š Architecture
Reddit API (via PRAW)
        â†“
Airflow DAG (Scheduled Extract)
        â†“
PostgreSQL (Raw data storage)
        â†“
Airflow + Celery Executor (Task orchestration inside Docker)
        â†“
PySpark Job (Data Transformation)
        â†“
AWS S3 (Raw & Transformed data storage)
        â†“
AWS Glue Job (Further transformation/cleaning)
        â†“
AWS Glue Crawler (Schema discovery, creates Data Catalog tables)
        â†“
AWS Athena (Query data from S3 and validate)
        â†“
Load into AWS Redshift (Native tables)
        â†“
Amazon QuickSight (Visualization & Dashboard)

##  Tech Stack
- **Apache Airflow** â€“ Workflow orchestration
- **Celery** â€“ Distributed task queue
- **PostgreSQL** â€“ Intermediate database
- **AWS S3** â€“ Data lake (raw & transformed storage)
- **AWS Glue** â€“ Data ETL jobs using PySpark
- **AWS Crawler** â€“ Metadata cataloging
- **AWS Athena** â€“ SQL querying on S3
- **Amazon Redshift** â€“ Data warehousing
- **Amazon QuickSight** â€“ Data visualization
- **Docker** â€“ Containerization & environment setup
- **PRAW** (Python Reddit API Wrapper) â€“ Reddit data extraction

## ğŸ”„Workflow Overview
### 1ï¸âƒ£Reddit Data Extraction
- Reddit posts are extracted using PRAW via a custom Airflow DAG.
- Stored as CSV in local storage.
### 2ï¸âƒ£Upload to AWS S3
Raw CSV data is uploaded to s3://reddit-pipeline-bejin/raw/.

### 3ï¸âƒ£AWS Glue ETL
A Glue job processes the CSV data, combines columns, and writes transformed data to s3://reddit-pipeline-bejin/transformed/.

### 4ï¸âƒ£Crawler & Athena
- AWS Glue Crawler catalogs the transformed data.
- AWS Athena is used for query verification.

### 5ï¸âƒ£Redshift Integration
Athena data is loaded into Redshift (reddit_namespace â†’ reddit-workgroup) as reddit_data_eng.

### 6ï¸âƒ£Data Visualization

QuickSight connects to Redshift and visualizes insights such as:
- ğŸ“Š Top 10 Reddit Authors by Total Score (Bar Chart)
- ğŸ“‰ Hourly Average Reddit Score Trend (Line Chart)
- ğŸ“ˆ Distribution of Reddit Post Scores (Histogram)
- ğŸ¥§ NSFW Status of Reddit Posts (Pie Chart â€“ All SFW Content)

### 7ï¸âƒ£Docker Setup for Local Development
To run the Airflow DAGs locally:
```
docker-compose up --build
```
Access the Airflow UI at:
```
 http://localhost:8081
```









